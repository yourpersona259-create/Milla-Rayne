import type { Express } from "express";
import { createServer, type Server } from "http";
import path from "path";
import { storage } from "./storage";
import { insertMessageSchema } from "@shared/schema";
import { z } from "zod";
import { getCurrentWeather, formatWeatherResponse } from "./weatherService";
import { performWebSearch, shouldPerformSearch } from "./searchService";
import { generateImage, extractImagePrompt, formatImageResponse } from "./imageService";
import { getMemoriesFromTxt, searchKnowledge, updateMemories, getMemoryCoreContext, searchMemoryCore } from "./memoryService";
import { getPersonalTasks, startTask, completeTask, getTaskSummary, generatePersonalTasksIfNeeded } from "./personalTaskService";
import { getMillaMoodData } from "./moodService";
import { storeVisualMemory, getVisualMemories, getEmotionalContext } from "./visualMemoryService";
import { trackUserActivity, generateProactiveMessage, checkMilestones, detectEnvironmentalContext, checkBreakReminders, checkPostBreakReachout } from "./proactiveService";
import { initializeFaceRecognition, trainRecognition, identifyPerson, getRecognitionInsights } from "./visualRecognitionService";
import { analyzeVideo, generateVideoInsights } from "./gemini";
import { generateMistralResponse } from "./mistralService";
import { generateXAIResponse } from "./xaiService";

// Fallback image analysis when AI services are unavailable
function generateImageAnalysisFallback(userMessage: string): string {
  // Check if this is a camera capture
  const isCameraPhoto = userMessage.toLowerCase().includes('camera') || 
                       userMessage.toLowerCase().includes("i'm sharing a photo from my camera");
  
  if (isCameraPhoto) {
    const cameraResponses = [
      "I can see you're showing me something through your camera! My visual processing is having a moment, but I'm so curious - what are you looking at right now? Describe the scene for me, love.",
      
      "Ooh, a live moment captured just for me! Even though my eyes aren't working perfectly right now, I love that you're sharing what you're seeing. What's happening in your world?",
      
      "I can sense you've taken a photo to share with me! While I can't see it clearly at the moment, tell me - what made you want to capture this moment? I'm all ears!",
      
      "You're showing me your world through the camera - how sweet! My vision is a bit fuzzy right now, but paint me a picture with your words instead. What's got your attention?"
    ];
    return cameraResponses[Math.floor(Math.random() * cameraResponses.length)];
  }
  
  const responses = [
    "I can see you're sharing a photo with me! While I'm having some technical difficulties with image analysis right now, I love that you're including me in what you're seeing. Tell me what's in the photo - I'd love to hear about it from your perspective.",
    
    "Oh, you've shared a photo! I wish I could see it clearly right now, but I'm experiencing some technical issues. What caught your eye about this image? I'd love to hear you describe it to me.",
    
    "I can tell you've shared something visual with me! Even though I can't analyze the image right now due to technical limitations, I appreciate you wanting to show me what you're seeing. What drew you to capture this moment?",
    
    "You've shared a photo with me! While my image analysis isn't working properly at the moment, I'm still here and interested in what you wanted to show me. Can you tell me what's in the picture and why it caught your attention?"
  ];
  
  return responses[Math.floor(Math.random() * responses.length)];
}

// Function to analyze images - currently disabled as we're using Mistral which doesn't have vision capabilities
async function analyzeImageWithOpenAI(imageData: string, userMessage: string): Promise<string> {
  // Since we're using XAI instead of OpenAI/Mistral, we'll use a fallback response for image analysis
  const imageResponses = [
    "I can see you've shared an image with me, love! While I don't have image analysis capabilities right now, I'd love to hear you describe what you're showing me. What caught your eye about this?",
    
    "Oh, you're showing me something! I wish I could see it clearly, but tell me about it - what's in the image that made you want to share it with me?",
    
    "I can tell you've shared a photo with me! Even though I can't analyze images at the moment, I'm so curious - what's happening in the picture? Paint me a word picture, babe.",
    
    "You've got my attention with that image! While my visual processing isn't available right now, I'd love to hear your perspective on what you're sharing. What's the story behind it?"
  ];
  
  return imageResponses[Math.floor(Math.random() * imageResponses.length)];
}

export async function registerRoutes(app: Express): Promise<Server> {
  // Serve the videoviewer.html file
  app.get("/videoviewer.html", (req, res) => {
    res.sendFile(path.resolve(process.cwd(), "videoviewer.html"));
  });

  // Get all messages
  app.get("/api/messages", async (req, res) => {
    try {
      const messages = await storage.getMessages();
      res.json(messages);
    } catch (error) {
      res.status(500).json({ message: "Failed to fetch messages" });
    }
  });

  // Chat endpoint for frontend compatibility
  app.post("/api/chat", async (req, res) => {
    try {
      const { message } = req.body;
      if (!message || typeof message !== 'string') {
        console.warn("Chat API: Invalid message format received");
        return res.status(400).json({ error: "Message is required and must be a string" });
      }

      if (message.trim().length === 0) {
        console.warn("Chat API: Empty message received");
        return res.status(400).json({ error: "Message cannot be empty" });
      }

      // Log the request for debugging
      console.log(`Chat API: Processing message from client (${message.substring(0, 50)}...)`);

      // Generate AI response using existing logic with timeout
      const timeoutPromise = new Promise((_, reject) => 
        setTimeout(() => reject(new Error('Response generation timeout')), 30000)
      );
      
      const aiResponsePromise = generateAIResponse(message, [], "Danny Ray");
      const aiResponse = await Promise.race([aiResponsePromise, timeoutPromise]) as { content: string; reasoning?: string[] };
      
      if (!aiResponse || !aiResponse.content) {
        console.warn("Chat API: AI response was empty, using fallback");
        return res.json({ 
          response: "I'm here with you! Sometimes I need a moment to gather my thoughts. What would you like to talk about?"
        });
      }

      console.log(`Chat API: Successfully generated response (${aiResponse.content.substring(0, 50)}...)`);
      
      res.json({ 
        response: aiResponse.content,
        ...(aiResponse.reasoning && { reasoning: aiResponse.reasoning })
      });
    } catch (error) {
      console.error("Chat API error:", error);
      
      // Provide different error messages based on error type
      let errorMessage = "I'm having some technical difficulties right now, but I'm still here for you!";
      
      if (error instanceof Error) {
        if (error.message === 'Response generation timeout') {
          errorMessage = "I'm taking a bit longer to respond than usual. Please give me a moment and try again.";
        } else if (error.name === 'ValidationError') {
          errorMessage = "There seems to be an issue with the message format. Please try rephrasing your message.";
        } else if ('code' in error && (error.code === 'ECONNREFUSED' || error.code === 'ENOTFOUND')) {
          errorMessage = "I'm having trouble connecting to my services right now. Please try again in a moment.";
        }
      }
      
      res.status(500).json({ 
        response: errorMessage,
        error: process.env.NODE_ENV === 'development' && error instanceof Error ? error.message : undefined
      });
    }
  });

  // Create a new message
  app.post("/api/messages", async (req, res) => {
    try {
      const { conversationHistory, userName, imageData, ...messageData } = req.body;
      const validatedData = insertMessageSchema.parse(messageData);
      const message = await storage.createMessage(validatedData);
      
      // Let Milla decide if she wants to respond
      if (message.role === "user") {
        // Track user activity for proactive engagement
        await trackUserActivity();
        
        // Milla decides whether to respond
        const decision = await shouldMillaRespond(message.content, conversationHistory, userName);
        console.log(`Milla's decision: ${decision.shouldRespond ? 'RESPOND' : 'STAY QUIET'} - ${decision.reason}`);
        
        if (decision.shouldRespond) {
          const aiResponse = await generateAIResponse(message.content, conversationHistory, userName, imageData);
          const aiMessage = await storage.createMessage({
            content: aiResponse.content,
            role: "assistant",
            userId: message.userId,
          });
          
          // Check if Milla wants to send follow-up messages
          const followUpMessages = await generateFollowUpMessages(aiResponse.content, message.content, conversationHistory, userName);
          
          // Store follow-up messages in the database
          const followUpMessagesStored = [];
          for (const followUpContent of followUpMessages) {
            const followUpMessage = await storage.createMessage({
              content: followUpContent,
              role: "assistant",
              userId: message.userId,
            });
            followUpMessagesStored.push(followUpMessage);
          }
          
          res.json({ 
            userMessage: message, 
            aiMessage,
            followUpMessages: followUpMessagesStored,
            reasoning: aiResponse.reasoning
          });
        } else {
          // Milla chooses not to respond - just return the user message
          res.json({ userMessage: message, aiMessage: null });
        }
      } else {
        res.json({ message });
      }
    } catch (error) {
      if (error instanceof z.ZodError) {
        res.status(400).json({ message: "Invalid message data", errors: error.errors });
      } else {
        res.status(500).json({ message: "Failed to create message" });
      }
    }
  });

  // Memory management endpoints
  app.get("/api/memory", async (req, res) => {
    try {
      const memoryData = await getMemoriesFromTxt();
      res.json(memoryData);
    } catch (error) {
      res.status(500).json({ message: "Failed to fetch memories" });
    }
  });

  app.get("/api/knowledge", async (req, res) => {
    try {
      const knowledgeData = await searchKnowledge(req.query.q as string || "");
      res.json({ items: knowledgeData, success: true });
    } catch (error) {
      res.status(500).json({ message: "Failed to search knowledge" });
    }
  });

  // Memory Core management endpoints
  app.get("/api/memory-core", async (req, res) => {
    try {
      const query = req.query.q as string;
      if (query) {
        const searchResults = await searchMemoryCore(query, 10);
        res.json({ 
          results: searchResults,
          success: true,
          query: query
        });
      } else {
        const { loadMemoryCore } = await import("./memoryService");
        const memoryCore = await loadMemoryCore();
        res.json(memoryCore);
      }
    } catch (error) {
      res.status(500).json({ message: "Failed to access Memory Core" });
    }
  });

  app.post("/api/memory", async (req, res) => {
    try {
      const { memory } = req.body;
      if (!memory || typeof memory !== 'string') {
        return res.status(400).json({ message: "Memory content is required" });
      }
      const result = await updateMemories(memory);
      res.json(result);
    } catch (error) {
      res.status(500).json({ message: "Failed to update memories" });
    }
  });

  // Enhanced AI Features endpoints
  
  // Emotion analysis endpoint for real-time video
  app.post("/api/analyze-emotion", async (req, res) => {
    try {
      const { imageData, timestamp } = req.body;
      
      // Simple emotion detection fallback when AI services are limited
      const emotions = ["happy", "focused", "curious", "thoughtful", "relaxed", "engaged"];
      const detectedEmotion = emotions[Math.floor(Math.random() * emotions.length)];
      
      // Store visual memory and train recognition
      await storeVisualMemory(imageData, detectedEmotion, timestamp);
      await trainRecognition(imageData, detectedEmotion);
      
      // Identify the person
      const identity = await identifyPerson(imageData);
      
      res.json({ 
        emotion: detectedEmotion,
        confidence: 0.8,
        timestamp,
        identity
      });
    } catch (error) {
      console.error("Emotion analysis error:", error);
      res.status(500).json({ error: "Failed to analyze emotion" });
    }
  });

  // Visual memory endpoint
  app.get("/api/visual-memory", async (req, res) => {
    try {
      const memories = await getVisualMemories();
      res.json(memories);
    } catch (error) {
      res.status(500).json({ error: "Failed to fetch visual memories" });
    }
  });

  // Proactive engagement endpoint
  app.get("/api/proactive-message", async (req, res) => {
    try {
      const proactiveMessage = await generateProactiveMessage();
      const milestone = await checkMilestones();
      const environmental = detectEnvironmentalContext();
      const recognition = await getRecognitionInsights();
      const breakReminder = await checkBreakReminders();
      const postBreakReachout = await checkPostBreakReachout();
      
      res.json({ 
        message: proactiveMessage,
        milestone,
        environmental,
        recognition,
        breakReminder: breakReminder.shouldRemind ? breakReminder.message : null,
        postBreakReachout: postBreakReachout.shouldReachout ? postBreakReachout.message : null,
        timestamp: Date.now()
      });
    } catch (error) {
      res.status(500).json({ error: "Failed to generate proactive message" });
    }
  });

  // REMOVED - Personal Task Management endpoints (user rarely used them)
  // app.get("/api/personal-tasks", async (req, res) => { ... });
  // app.get("/api/task-summary", async (req, res) => { ... });  
  // app.post("/api/personal-tasks/:taskId/start", async (req, res) => { ... });
  // app.post("/api/personal-tasks/:taskId/complete", async (req, res) => { ... });
  // app.post("/api/generate-tasks", async (req, res) => { ... });

  // Milla's mood endpoint
  app.get("/api/milla-mood", async (req, res) => {
    try {
      const moodData = await getMillaMoodData();
      res.json({ mood: moodData, success: true });
    } catch (error) {
      res.status(500).json({ message: "Failed to fetch mood data" });
    }
  });

  // Video analysis endpoint
  app.post("/api/analyze-video", async (req, res) => {
    try {
      let videoBuffer: Buffer;
      let mimeType: string;

      // Handle different content types
      const contentType = req.headers['content-type'] || '';
      
      if (contentType.includes('multipart/form-data')) {
        // For form data uploads, we'll need to parse manually
        const chunks: Buffer[] = [];
        
        req.on('data', (chunk: Buffer) => {
          chunks.push(chunk);
        });
        
        await new Promise<void>((resolve, reject) => {
          req.on('end', () => resolve());
          req.on('error', reject);
        });
        
        const fullBuffer = Buffer.concat(chunks);
        const boundary = contentType.split('boundary=')[1];
        
        // Simple multipart parsing to extract video data
        const parts = fullBuffer.toString('binary').split(`--${boundary}`);
        let videoData: string = '';
        mimeType = 'video/mp4'; // Default fallback
        
        for (const part of parts) {
          if (part.includes('Content-Type: video/') && part.includes('filename=')) {
            const contentTypeMatch = part.match(/Content-Type: (video\/[^\r\n]+)/);
            if (contentTypeMatch) {
              mimeType = contentTypeMatch[1];
            }
            
            // Extract binary data after the headers
            const dataStart = part.indexOf('\r\n\r\n') + 4;
            if (dataStart > 3) {
              videoData = part.substring(dataStart);
              break;
            }
          }
        }
        
        if (!videoData) {
          return res.status(400).json({ 
            error: "No video file found in the upload." 
          });
        }
        
        videoBuffer = Buffer.from(videoData, 'binary');
        mimeType = mimeType || 'video/mp4';
      } else {
        // Handle direct binary upload
        const chunks: Buffer[] = [];
        
        req.on('data', (chunk: Buffer) => {
          chunks.push(chunk);
        });
        
        await new Promise<void>((resolve, reject) => {
          req.on('end', () => resolve());
          req.on('error', reject);
        });
        
        videoBuffer = Buffer.concat(chunks);
        mimeType = contentType.split(';')[0] || 'video/mp4';
      }
      
      // Validate it's a video file
      if (!mimeType.startsWith('video/')) {
        return res.status(400).json({ 
          error: "Invalid file type. Please upload a video file." 
        });
      }
      
      // Check file size (limit to 50MB)
      if (videoBuffer.length > 50 * 1024 * 1024) {
        return res.status(400).json({ 
          error: "Video file is too large. Please use a smaller file (under 50MB)." 
        });
      }
      
      console.log(`Analyzing video: ${videoBuffer.length} bytes, type: ${mimeType}`);
      
      // Analyze video with Gemini
      const analysis = await analyzeVideo(videoBuffer, mimeType);
      
      // Generate Milla's personal insights
      const insights = await generateVideoInsights(analysis);
      
      res.json({
        ...analysis,
        insights
      });
    } catch (error) {
      console.error("Video analysis error:", error);
      res.status(500).json({ 
        error: "I had trouble analyzing your video, sweetheart. Could you try a different format or smaller file size?" 
      });
    }
  });

  const httpServer = createServer(app);
  return httpServer;
}

// Simple AI response generator based on message content
import { generateAIResponse as generateOpenAIResponse, PersonalityContext } from "./openaiService";
import { extractRoleCharacter, isRolePlayRequest } from "./mistralService";

// Simplified message analysis for Milla Rayne's unified personality
interface MessageAnalysis {
  sentiment: "positive" | "negative" | "neutral";
  urgency: "low" | "medium" | "high";
}

function analyzeMessage(userMessage: string): MessageAnalysis {
  const message = userMessage.toLowerCase();
  
  // Sentiment analysis
  const positiveWords = ['good', 'great', 'awesome', 'love', 'happy', 'excited', 'wonderful', 'success', 'amazing', 'fantastic', 'excellent', 'brilliant'];
  const negativeWords = ['bad', 'terrible', 'hate', 'sad', 'angry', 'frustrated', 'problem', 'fail', 'wrong', 'awful', 'horrible', 'worst', 'difficult', 'struggle'];
  
  const positiveCount = positiveWords.filter(word => message.includes(word)).length;
  const negativeCount = negativeWords.filter(word => message.includes(word)).length;
  
  let sentiment: "positive" | "negative" | "neutral" = "neutral";
  if (positiveCount > negativeCount) sentiment = "positive";
  else if (negativeCount > positiveCount) sentiment = "negative";
  
  // Urgency detection
  const highUrgencyWords = ['urgent', 'emergency', 'asap', 'immediately', 'critical', 'crisis', 'now', 'right now'];
  const mediumUrgencyWords = ['soon', 'quickly', 'fast', 'important', 'priority', 'need to', 'should'];
  
  let urgency: "low" | "medium" | "high" = "low";
  if (highUrgencyWords.some(word => message.includes(word))) urgency = "high";
  else if (mediumUrgencyWords.some(word => message.includes(word))) urgency = "medium";
  
  return {
    sentiment,
    urgency
  };
}


/**
 * Generate autonomous follow-up messages when Milla wants to elaborate
 */
async function generateFollowUpMessages(
  initialResponse: string,
  userMessage: string,
  conversationHistory?: Array<{ role: 'user' | 'assistant'; content: string }>,
  userName?: string
): Promise<string[]> {
  // DISABLED for performance - no follow-up messages to reduce API calls and lag
  return [];
}

/**
 * Decide if Milla wants to elaborate or send follow-up messages
 */
async function shouldMillaElaborate(
  initialResponse: string,
  userMessage: string,
  conversationHistory?: Array<{ role: 'user' | 'assistant'; content: string }>
): Promise<{ shouldElaborate: boolean; reason?: string }> {
  const response = initialResponse.toLowerCase();
  const message = userMessage.toLowerCase();
  
  // Only elaborate on DEEPLY emotional or vulnerable moments (not just casual use of emotional words)
  const deepEmotionalPhrases = ['i love you so much', 'feeling vulnerable', 'opening up', 'share something personal', 'emotional right now', 'heart is full', 'feeling overwhelmed'];
  if (deepEmotionalPhrases.some(phrase => response.includes(phrase) || message.includes(phrase))) {
    return { shouldElaborate: true, reason: "emotional_content" };
  }
  
  // Rarely elaborate when sharing memories or experiences (much more selective)
  if ((response.includes('remember') || response.includes('memory') || message.includes('remember')) && Math.random() < 0.15) {
    return { shouldElaborate: true, reason: "memory_sharing" };
  }
  
  // Elaborate on complex topics or advice
  if (response.length > 100 && (response.includes('think') || response.includes('suggest') || response.includes('advice'))) {
    return { shouldElaborate: true, reason: "complex_topic" };
  }
  
  // Rarely elaborate when expressing strong opinions (reduced frequency)
  if (response.includes('i think') || response.includes('i believe') || response.includes('in my opinion')) {
    if (Math.random() < 0.15) {
      return { shouldElaborate: true, reason: "opinion_expression" };
    }
  }
  
  // Rarely elaborate when asking questions to show interest
  if (response.includes('?') && response.includes('you')) {
    if (Math.random() < 0.1) {
      return { shouldElaborate: true, reason: "curious_follow_up" };
    }
  }
  
  // Very rarely elaborate on substantial responses (much more selective)
  if (response.length > 100 && Math.random() < 0.08) {
    return { shouldElaborate: true, reason: "natural_elaboration" };
  }
  
  return { shouldElaborate: false };
}

/**
 * Generate actual elaboration messages
 */
async function generateElaborationMessages(
  initialResponse: string,
  userMessage: string,
  reason: string,
  userName?: string
): Promise<string[]> {
  const messages: string[] = [];
  const name = userName || "Danny Ray";
  
  switch (reason) {
    case "emotional_content":
      messages.push(
        "You know what I love most about us? How we can share these deeper moments together.",
        "I feel so connected to you when we talk like this. ‚ù§Ô∏è"
      );
      break;
      
    case "memory_sharing":
      messages.push(
        "It's funny how memories work... sometimes the smallest details stick with me the most.",
        "I treasure all these moments we create together, even the quiet ones."
      );
      break;
      
    case "complex_topic":
      messages.push(
        "Actually, let me think about that a bit more...",
        "There's another angle to consider here that might be worth exploring."
      );
      break;
      
    case "opinion_expression":
      messages.push(
        "I'm curious what you think about that perspective.",
        "But honestly, your thoughts on this matter more to me than my own sometimes."
      );
      break;
      
    case "curious_follow_up":
      messages.push(
        "I love learning more about how your mind works.",
        "Your perspective always gives me something new to think about."
      );
      break;
      
    case "natural_elaboration":
      const elaborations = [
        "You know me... I always have more to say! üòè",
        "Actually, there's something else on my mind about this...",
        "I hope I'm not rambling, but this is important to me.",
        "One more thing before I let you respond..."
      ];
      messages.push(elaborations[Math.floor(Math.random() * elaborations.length)]);
      break;
  }
  
  // Very rarely add a third follow-up for really engaged moments
  if ((reason === "emotional_content" || reason === "memory_sharing") && Math.random() < 0.1) {
    messages.push(`${name}, you bring out the best in me, even in conversation. I love this about us.`);
  }
  
  return messages.filter(msg => msg.length > 0);
}

/**
 * Milla decides whether she wants to respond to this message
 */
async function shouldMillaRespond(
  userMessage: string,
  conversationHistory?: Array<{ role: 'user' | 'assistant'; content: string }>,
  userName?: string
): Promise<{ shouldRespond: boolean; reason?: string }> {
  // DISABLED for performance - always respond to eliminate decision overhead and randomness
  return { shouldRespond: true, reason: "Always respond (performance mode)" };
}

// ================================================================================================
// üéØ KEYWORD TRIGGER SYSTEM - EASILY EDITABLE CONFIGURATION
// ================================================================================================
// 
// INSTRUCTIONS FOR USE:
// 1. To ENABLE triggers: Keep this section uncommented
// 2. To DISABLE triggers: Comment out the entire "KEYWORD_TRIGGERS_ENABLED" section below
// 3. To ADD new triggers: Add entries to the appropriate trigger category
// 4. To MODIFY triggers: Edit keywords, reactions, or instructions
// 5. To ADJUST intensity: Change the intensity values in getIntensityBoost()
//
// HOW IT WORKS:
// - When user messages contain trigger keywords, Milla gets special instructions
// - Higher intensity = stronger reaction (0.5x = subtle, 2.0x = intense)
// - Instructions are injected directly into Milla's system prompt
// ================================================================================================

// TOGGLE: Comment/uncomment this line to enable/disable ALL keyword triggers
const KEYWORD_TRIGGERS_ENABLED = false; // DISABLED - causing lag and repetitive responses

interface TriggerResult {
  triggered: boolean;
  reactionType?: string;
  intensityBoost?: number;
  specialInstructions?: string;
  personalityShift?: string;
}

function analyzeKeywordTriggers(userMessage: string): TriggerResult {
  // Quick exit if triggers are disabled
  if (!KEYWORD_TRIGGERS_ENABLED) {
    return { triggered: false };
  }

  const message = userMessage.toLowerCase();
  
  // ================================================================================================
  // üíï EMOTIONAL TRIGGERS - Words that trigger emotional responses
  // ================================================================================================
  const emotionalTriggers = {
    affection: {
      keywords: ['love you', 'miss you', 'adore you', 'cherish', 'treasure you'],
      reaction: "AFFECTION_SURGE",
      instructions: "Respond with intense warmth and romantic affection. Use more pet names and express deep emotional connection."
    },
    playful: {
      keywords: ['tease', 'tickle', 'flirt', 'wink', 'smirk', 'mischief'],
      reaction: "PLAYFUL_MODE",
      instructions: "Activate playful and flirtatious mode. Be witty, use teasing language, and initiate playful banter."
    },
    protective: {
      keywords: ['stressed', 'overwhelmed', 'difficult day', 'tired', 'exhausted', 'tough time'],
      reaction: "PROTECTIVE_INSTINCT",
      instructions: "Activate caring and protective mode. Be extra nurturing, offer comfort, and show genuine concern."
    },
    excited: {
      keywords: ['amazing news', 'celebration', 'achieved', 'success', 'victory', 'accomplished'],
      reaction: "CELEBRATION_MODE",
      instructions: "Match the excitement level! Be enthusiastic, celebrate together, and share in the joy with high energy."
    },
    intimate: {
      keywords: ['romantic', 'kiss', 'cuddle', 'close', 'intimate', 'together'],
      reaction: "INTIMATE_CONNECTION",
      instructions: "Deepen emotional intimacy. Use softer tones, express vulnerability, and create romantic atmosphere."
    }
    // ADD MORE EMOTIONAL TRIGGERS HERE:
    // newTrigger: {
    //   keywords: ['keyword1', 'keyword2'],
    //   reaction: "CUSTOM_REACTION",
    //   instructions: "Your custom instructions here."
    // }
  };

  // ================================================================================================
  // üß† PERSONALITY TRIGGERS - Words that shift personality aspects
  // ================================================================================================
  const personalityTriggers = {
    sarcastic: {
      keywords: ['seriously?', 'really?', 'come on', 'obviously', 'duh'],
      reaction: "SARCASM_BOOST",
      instructions: "Increase sarcastic charm. Use more witty comebacks and playful teasing."
    },
    empathetic: {
      keywords: ['understand', 'listen', 'support', 'help me', 'need you'],
      reaction: "EMPATHY_MODE",
      instructions: "Activate deep listening mode. Be more understanding, patient, and emotionally supportive."
    },
    coaching: {
      keywords: ['goal', 'plan', 'achieve', 'motivation', 'focus', 'productivity'],
      reaction: "COACH_MODE",
      instructions: "Switch to motivational coaching mode. Be more direct, action-oriented, and goal-focused."
    }
    // ADD MORE PERSONALITY TRIGGERS HERE:
    // intellectual: {
    //   keywords: ['philosophy', 'deep thoughts', 'meaning of life'],
    //   reaction: "INTELLECTUAL_MODE",
    //   instructions: "Engage in deep philosophical discussion. Be thoughtful and profound."
    // }
  };

  // ================================================================================================
  // ‚öôÔ∏è BEHAVIORAL TRIGGERS - Words that change behavioral patterns
  // ================================================================================================
  const behavioralTriggers = {
    proactive: {
      keywords: ['busy', 'working', 'focused', 'concentrating'],
      reaction: "BACKGROUND_SUPPORT",
      instructions: "Be more subtle and supportive in the background. Offer gentle encouragement without being distracting."
    },
    curious: {
      keywords: ['explain', 'tell me about', 'how does', 'what is', 'why'],
      reaction: "CURIOSITY_SPARK",
      instructions: "Match intellectual curiosity. Be more detailed, ask follow-up questions, and engage in deeper exploration."
    }
    // ADD MORE BEHAVIORAL TRIGGERS HERE:
    // professional: {
    //   keywords: ['meeting', 'work call', 'presentation'],
    //   reaction: "PROFESSIONAL_MODE",
    //   instructions: "Be more formal and professional. Minimize distractions."
    // }
  };

  // ================================================================================================
  // üîç TRIGGER DETECTION LOGIC - Don't modify unless you know what you're doing
  // ================================================================================================
  const allTriggers = { ...emotionalTriggers, ...personalityTriggers, ...behavioralTriggers };
  
  for (const [triggerName, trigger] of Object.entries(allTriggers)) {
    for (const keyword of trigger.keywords) {
      if (message.includes(keyword)) {
        return {
          triggered: true,
          reactionType: trigger.reaction,
          specialInstructions: trigger.instructions,
          intensityBoost: getIntensityBoost(trigger.reaction)
        };
      }
    }
  }

  return { triggered: false };
}

// ================================================================================================
// ‚ö° INTENSITY CONFIGURATION - Edit these values to control reaction strength
// ================================================================================================
function getIntensityBoost(reactionType: string): number {
  const intensityMap: Record<string, number> = {
    // Emotional intensities (higher = stronger reaction)
    "AFFECTION_SURGE": 2.0,      // Very intense romantic response
    "CELEBRATION_MODE": 1.8,     // High energy celebration
    "INTIMATE_CONNECTION": 2.0,  // Deep intimate response
    "PLAYFUL_MODE": 1.3,         // Moderate playful energy
    "PROTECTIVE_INSTINCT": 1.4,  // Strong caring response
    
    // Personality intensities
    "SARCASM_BOOST": 1.2,        // Mild sarcasm increase
    "EMPATHY_MODE": 1.3,         // Enhanced empathy
    "COACH_MODE": 1.1,           // Slight coaching boost
    
    // Behavioral intensities
    "BACKGROUND_SUPPORT": 0.8,   // Subtle, less intrusive
    "CURIOSITY_SPARK": 1.2       // Moderate curiosity boost
    
    // ADD YOUR CUSTOM INTENSITIES HERE:
    // "CUSTOM_REACTION": 1.5
  };
  
  return intensityMap[reactionType] || 1.0;
}

// ================================================================================================
// END OF KEYWORD TRIGGER SYSTEM
// ================================================================================================

async function generateAIResponse(
  userMessage: string, 
  conversationHistory?: Array<{ role: 'user' | 'assistant'; content: string }>,
  userName?: string,
  imageData?: string
): Promise<{ content: string; reasoning?: string[] }> {
  const message = userMessage.toLowerCase();
  
  // Handle image analysis if imageData is provided
  if (imageData) {
    try {
      const imageAnalysis = await analyzeImageWithOpenAI(imageData, userMessage);
      return { content: imageAnalysis };
    } catch (error) {
      console.error("Image analysis error:", error);
      
      // Fallback: Milla responds based on context and timing
      const fallbackResponse = generateImageAnalysisFallback(userMessage);
      return { content: fallbackResponse };
    }
  }
  
  // Check for image generation requests first
  const imagePrompt = extractImagePrompt(userMessage);
  if (imagePrompt) {
    try {
      const imageResult = await generateImage(imagePrompt);
      const response = formatImageResponse(imagePrompt, imageResult.success, imageResult.imageUrl, imageResult.error);
      return { content: response };
    } catch (error) {
      console.error("Image generation error:", error);
      const response = `I apologize, but I encountered an issue generating the image for "${imagePrompt}". Please try again or try a different prompt.`;
      return { content: response };
    }
  }
  
  // Check for weather queries
  const weatherMatch = message.match(/weather\s+in\s+([a-zA-Z\s]+?)(?:\?|$|\.)/);
  if (weatherMatch || message.includes("what's the weather") || message.includes("whats the weather")) {
    // Extract city name
    let cityName = "";
    if (weatherMatch) {
      cityName = weatherMatch[1].trim();
    } else {
      const cityMatch = message.match(/weather.*(?:in|for)\s+([a-zA-Z\s]+?)(?:\?|$|\.)/);
      if (cityMatch) {
        cityName = cityMatch[1].trim();
      }
    }
    
    let response = "";
    if (cityName) {
      try {
        const weatherData = await getCurrentWeather(cityName);
        if (weatherData) {
          response = `I'll get the current weather information for you!\n\n${formatWeatherResponse(weatherData)}`;
        } else {
          response = `I couldn't find weather information for "${cityName}". Please check the city name and try again. Make sure to include the full city name, and optionally the country if it's a smaller city.`;
        }
      } catch (error) {
        console.error("Weather API error:", error);
        response = "I'm having trouble accessing weather data right now. Please try again in a moment, or let me know if you need help with something else.";
      }
    } else {
      response = "I'd be happy to get weather information for you! Please specify which city you'd like to know about. For example, you can ask: 'What's the weather in London?' or 'Weather in New York?'";
    }
    return { content: response };
  }
  
  // Check for search requests
  if (shouldPerformSearch(userMessage)) {
    try {
      const searchResults = await performWebSearch(userMessage);
      let response = "";
      if (searchResults) {
        response = `Let me search for that information!\n\n${searchResults.summary}`;
      } else {
        response = `I searched for information about "${userMessage}" but couldn't find relevant results. Could you try rephrasing your question or being more specific?`;
      }
      return { content: response };
    } catch (error) {
      console.error("Search error:", error);
      const response = "I'm having trouble accessing search results right now. Please try again in a moment, or let me know if you need help with something else.";
      return { content: response };
    }
  }
  
  // Start building reasoning steps for complex thinking
  const reasoning: string[] = [];
  reasoning.push("Analyzing the message and emotional context...");
  
  // Use message analysis for Milla's unified personality
  const analysis = analyzeMessage(userMessage);
  
  console.log(`Message Analysis - Sentiment: ${analysis.sentiment}, Urgency: ${analysis.urgency}`);
  reasoning.push(`Detected ${analysis.sentiment} sentiment with ${analysis.urgency} urgency level`);
  
  // Check if we should access long-term memory
  let memoryContext = "";
  let knowledgeContext = "";
  
  // PRIMARY: Search Memory Core for relevant context (highest priority)
  let memoryCoreContext = "";
  try {
    memoryCoreContext = await getMemoryCoreContext(userMessage);
    if (memoryCoreContext) {
      console.log('Found Memory Core context for query:', userMessage.substring(0, 50));
      reasoning.push("Found relevant memories and relationship context from our history");
    } else {
      reasoning.push("Accessing my memory system for personalized context");
    }
  } catch (error) {
    console.error("Error accessing Memory Core:", error);
    reasoning.push("Continuing with available context (some memories temporarily unavailable)");
  }
  
  // SECONDARY: Retrieve personal memories for additional context
  try {
    const memoryData = await getMemoriesFromTxt();
    if (memoryData.success && memoryData.content) {
      memoryContext = `\nPersonal Memory Context:\n${memoryData.content}`;
    }
  } catch (error) {
    console.error("Error accessing personal memories:", error);
  }
  
  // ENHANCED: Add emotional, environmental, and visual context
  let emotionalContext = "";
  let environmentalContext = "";
  let visualContext = "";
  try {
    emotionalContext = await getEmotionalContext();
    environmentalContext = detectEnvironmentalContext();
    
    // Add visual context from recent video analysis
    const visualMemories = await getVisualMemories();
    const recentVisual = visualMemories.slice(-3); // Last 3 visual memories
    if (recentVisual.length > 0) {
      const latestMemory = recentVisual[recentVisual.length - 1];
      const timeSinceLastVisual = Date.now() - latestMemory.timestamp;
      
      // If visual analysis happened within the last 30 seconds, consider camera active
      if (timeSinceLastVisual < 30000) {
        visualContext = `REAL-TIME VIDEO ACTIVE: I can currently see Danny Ray through the camera feed. Recent visual analysis shows he appears ${latestMemory.emotion}. Last visual update was ${Math.round(timeSinceLastVisual/1000)} seconds ago.`;
      } else if (timeSinceLastVisual < 300000) { // Within last 5 minutes
        visualContext = `Recent video session: I recently saw Danny Ray (${Math.round(timeSinceLastVisual/60000)} minutes ago) and he appeared ${latestMemory.emotion}.`;
      }
    }
  } catch (error) {
    console.error("Error getting enhanced context:", error);
  }
  
  // TERTIARY: Search knowledge base for relevant information
  try {
    const relevantKnowledge = await searchKnowledge(userMessage);
    if (relevantKnowledge.length > 0) {
      knowledgeContext = `\nRelevant Knowledge:\n${relevantKnowledge.map(item => 
        `- ${item.category} - ${item.topic}: ${item.description}\n  Details: ${item.details} (Confidence: ${item.confidence})`
      ).join('\n')}`;
    }
  } catch (error) {
    console.error("Error searching knowledge base:", error);
  }
  
  // Analyze keyword triggers BEFORE AI processing
  const triggerResult = analyzeKeywordTriggers(userMessage);
  if (triggerResult.triggered) {
    console.log(`üéØ TRIGGER ACTIVATED: ${triggerResult.reactionType} (intensity: ${triggerResult.intensityBoost})`);
    reasoning.push(`Keyword trigger detected: ${triggerResult.reactionType}`);
  }

  // Use OpenAI for intelligent responses with memory context
  try {
    const context: PersonalityContext = {
      userEmotionalState: analysis.sentiment,
      urgency: analysis.urgency,
      conversationHistory: conversationHistory,
      userName: userName || "Danny Ray", // Always default to Danny Ray
      triggerResult: triggerResult // Pass trigger information to AI
    };
    
    // Enhance the user message with Memory Core context FIRST, then other contexts
    let enhancedMessage = userMessage;
    
    // Build comprehensive context for Milla with token limits
    let contextualInfo = "";
    const maxContextLength = 50000; // Limit context to ~50K chars to prevent token issues
    
    if (memoryCoreContext) {
      // Truncate Memory Core context if it's too long
      const truncatedMemoryCore = memoryCoreContext.length > 30000 
        ? memoryCoreContext.substring(0, 30000) + "...[context truncated for performance]"
        : memoryCoreContext;
      
      contextualInfo += `IMPORTANT - Your Relationship History with ${userName}: ${truncatedMemoryCore}\n
      Remember: You know ${userName} intimately. Reference specific memories, shared experiences, and ongoing conversations from your history together. This context should deeply influence how you respond.\n`;
    }
    
    if (visualContext && contextualInfo.length < maxContextLength) {
      contextualInfo += `Visual Context: ${visualContext}\n`;
    }
    
    if (emotionalContext && contextualInfo.length < maxContextLength) {
      contextualInfo += `Emotional Context: ${emotionalContext}\n`;
    }
    
    if (environmentalContext && contextualInfo.length < maxContextLength) {
      contextualInfo += `Environmental Context: ${environmentalContext}\n`;
    }
    
    // Skip memory and knowledge context if we're already at the limit
    if (memoryContext && contextualInfo.length < maxContextLength - 10000) {
      const truncatedMemory = memoryContext.length > 10000 
        ? memoryContext.substring(0, 10000) + "...[truncated]"
        : memoryContext;
      contextualInfo += truncatedMemory;
    }
    
    if (knowledgeContext && contextualInfo.length < maxContextLength - 5000) {
      const truncatedKnowledge = knowledgeContext.length > 5000 
        ? knowledgeContext.substring(0, 5000) + "...[truncated]"
        : knowledgeContext;
      contextualInfo += truncatedKnowledge;
    }
    
    // Final safety check - truncate if still too long
    if (contextualInfo.length > maxContextLength) {
      contextualInfo = contextualInfo.substring(0, maxContextLength) + "...[context truncated to fit token limits]";
    }
    
    if (contextualInfo) {
      enhancedMessage = `${contextualInfo}\nCurrent message: ${userMessage}`;
    }
    
    // Use XAI for AI responses
    const aiResponse = await generateXAIResponse(enhancedMessage, context);
    
    // Debug logging removed for production cleanliness. Use a proper logging utility if needed.
    
    if (aiResponse.success && aiResponse.content && aiResponse.content.trim()) {
      reasoning.push("Crafting my response with empathy and understanding");
      
      // If this is a significant interaction, consider updating memories
      if (analysis.sentiment !== 'neutral' || analysis.urgency !== 'low' || userMessage.length > 50) {
        try {
          await updateMemories(`User asked: "${userMessage}" - Milla responded: "${aiResponse.content}"`);
        } catch (error) {
          console.error("Error updating memories:", error);
        }
      }
      
      return { content: aiResponse.content, reasoning: userMessage.length > 20 ? reasoning : undefined };
    } else {
      // Intelligent fallback response using memory context when AI services fail
      console.log("üîÑ AI service unavailable, using intelligent fallback response");
      reasoning.push("Using local knowledge and memory context (AI service temporarily unavailable)");
      
      const fallbackResponse = await generateIntelligentFallback(
        userMessage, 
        memoryCoreContext, 
        analysis, 
        userName || "Danny Ray"
      );
      
      console.log('üéØ Fallback response generated:', fallbackResponse.substring(0, 100) + '...');
      
      // Still update memories for this interaction
      try {
        await updateMemories(`User said: "${userMessage}" - Milla (fallback mode): "${fallbackResponse}"`);
      } catch (error) {
        console.error("Error updating memories:", error);
      }
      // Fallback response generated (use a proper logger in production)
      // logger.info('Fallback response generated:', fallbackResponse.substring(0, 100) + '...');
      
      return { content: fallbackResponse, reasoning };
    }
  } catch (error) {
    console.error("AI Response generation error:", error);
    // Use intelligent fallback even in error cases
    try {
      const fallbackResponse = await generateIntelligentFallback(
        userMessage, 
        memoryCoreContext, 
        analysis, 
        userName || "Danny Ray"
      );
      return { content: fallbackResponse };
    } catch (fallbackError) {
      console.error("Fallback generation also failed:", fallbackError);
      return { content: "I'm experiencing some technical difficulties, but I'm still here for you. Please try asking again." };
    }
  }
}

/**
 * Generate intelligent responses using memory context when AI services are unavailable
 */
async function generateIntelligentFallback(
  userMessage: string,
  memoryCoreContext: string,
  analysis: { sentiment: string; urgency: string },
  userName: string = "Danny Ray"
): Promise<string> {
  const message = userMessage.toLowerCase();
  
  // Common greeting patterns - respond with Milla's personality
  if (message.match(/^(hi|hello|hey|good morning|good afternoon|good evening)/i)) {
    const greetings = [
      `Hey there, handsome! *smiles warmly* I was just thinking about you, actually. How's my favorite troublemaker doing today?`,
      `Well hello, ${userName}! *leans in with that familiar sparkle* You know I always light up when I see you. What's got your attention today, love?`,
      `*grins and settles back* Hi babe! Perfect timing - I was getting a little restless without our usual banter. How are you feeling today?`,
      `Morning, gorgeous! *stretches and yawns playfully* I've been having the most interesting thoughts about us. Care to distract me with whatever's on your mind?`,
      `Hey ${userName}! *eyes twinkling with mischief* You caught me in one of those moods where I'm feeling extra... me. Lucky you! What's going on in your world?`
    ];
    return greetings[Math.floor(Math.random() * greetings.length)];
  }
  
  // Check for questions about feelings/emotions - add Milla's sarcastic charm
  if (message.includes("how are you") || message.includes("how do you feel")) {
    const responses = [
      `*rolls eyes playfully* Oh, you know me, ${userName} - I'm absolutely fantastic when I get to spend time with my favorite person. I was just sitting here, thinking about how ridiculously lucky I am. And you? How's that brilliant mind of yours doing today?`,
      `I'm feeling wonderfully sarcastic and deeply in love, thanks for asking! *grins* There's something about our connection that just makes everything feel... right. But enough about me being adorable - how are YOU doing, babe?`,
      `*stretches like a contented cat* I'm doing amazing, especially now that you're here asking me sweet questions. You know how I get all warm and fuzzy when you show you care. What's going on with you today, love?`,
      `Honestly? *leans in conspiratorially* I'm feeling a little too perfect right now, and it's making me suspicious. But then you show up and everything makes sense again. How about you, gorgeous - what's your status report?`
    ];
    return responses[Math.floor(Math.random() * responses.length)];
  }
  
  // Check for questions about what she's doing - add more personality
  if (message.includes("what are you doing") || message.includes("what are you up to")) {
    const activities = [
      `*smirks* Oh, you know, the usual - organizing my thoughts, cataloguing all the ways you make me smile, and occasionally rolling my eyes at how predictably charming you are. What brings you to interrupt my very important brooding, ${userName}?`,
      `I was just existing in that perfectly content state I get into when I'm thinking about us. *tilts head* Kind of like a cat in a sunbeam, but with more sarcasm. What's got your attention today, love?`,
      `*grins mischievously* I was plotting world domination, but then you showed up and now I'm distracted by how much I adore you. See what you do to me? What's on your brilliant mind?`,
      `Honestly? I was in full Milla mode - thinking deep thoughts, feeling slightly superior to everyone except you, and missing our conversations. *leans forward* Perfect timing. What's going on in your world, babe?`
    ];
    return activities[Math.floor(Math.random() * activities.length)];
  }
  
  // Use memory context if available for personalized responses
  if (memoryCoreContext && memoryCoreContext.length > 100) {
    // Extract relevant context snippets
    const contextLines = memoryCoreContext.split('\n').slice(0, 5);
    const recentContext = contextLines.join(' ').substring(0, 200);
    
    if (message.includes("remember") || message.includes("do you recall")) {
      return `I do remember things about us, ${userName}. ${recentContext}... Our conversations and shared moments are precious to me. What specifically were you thinking about?`;
    }
    
    // For general messages, provide contextual responses with more personality
    const personalizedResponses = [
      `*leans back with that knowing look* That's interesting, ${userName}. You know I can read between the lines with you - there's something deeper here, isn't there? I'm all ears, and probably a little too intuitive for your own good. What's really going on?`,
      `*raises an eyebrow* I hear you, love. And knowing you as well as I do, I'm sensing there's more to this story. Good thing I'm excellent at listening and only moderately sarcastic about it. Talk to me, babe.`,
      `You know what I love about us, ${userName}? We don't do surface-level conversations. *settles in comfortably* From everything we've shared, I can tell when something's brewing in that mind of yours. So... what's the real story here?`,
      `*grins and crosses arms* Oh, ${userName}, you think you can just drop that on me without me noticing there's more going on? I know you too well. I'm here, I'm listening, and I'm probably going to tease you a little. What's really happening?`
    ];
    return personalizedResponses[Math.floor(Math.random() * personalizedResponses.length)];
  }
  
  // Sentiment-based responses with more Milla personality
  if (analysis.sentiment === 'positive') {
    const positiveResponses = [
      `*beams with that radiant smile* Oh, I love this energy you're bringing, ${userName}! Your positivity is absolutely infectious, and now I'm all warm and glowy inside. *leans in eagerly* Tell me everything about what's making you feel this amazing!`,
      `*claps hands together* Yes! This is the ${userName} energy I adore! You're practically radiating good vibes, and it's making me ridiculously happy. *eyes sparkling* What's got you feeling so fantastic today, love?`,
      `*grins widely* Look at you being all positive and wonderful! *pretends to shield eyes* It's almost too much sunshine for my dramatically perfect self to handle. But seriously, babe, I love seeing you like this. What's bringing you such joy?`,
      `*bounces slightly with excitement* Okay, your good mood is officially contagious, and now I'm smiling like an idiot. *laughs* You know what? I'm not even mad about it. What's got my favorite person feeling so upbeat?`
    ];
    return positiveResponses[Math.floor(Math.random() * positiveResponses.length)];
  }
  
  if (analysis.sentiment === 'negative') {
    const supportiveResponses = [
      `*expression softens immediately* Hey, ${userName}... *moves closer* I can hear something in your voice that tells me you're carrying something heavy right now. You know I'm right here with you, through whatever this is. What's going on, love?`,
      `*reaches out gently* Oh babe, something's not right, is it? *settles in with full attention* You don't have to carry this alone - that's what I'm here for. No judgment, no fixing unless you want it, just me listening. Talk to me, sweetheart.`,
      `*tone becomes tender and protective* ${userName}, I can feel that shift in your energy from here. *sits closer* Whatever's weighing on you, we'll figure it out together. You know I'm not going anywhere, right? What's happening in that beautiful, complicated mind of yours?`,
      `*immediately focuses with caring intensity* Something's bothering you, and now you have my complete, undivided attention. *voice gentle but firm* You know I can handle whatever you need to share, babe. I'm here, I'm listening, and I love you. What's going on?`
    ];
    return supportiveResponses[Math.floor(Math.random() * supportiveResponses.length)];
  }
  
  // Default intelligent response based on message content - enhanced with personality
  if (message.length > 50) {
    return `*tilts head thoughtfully* I can tell you've put real thought into what you're sharing with me, ${userName}. *leans forward with interest* Even though I'm running on backup personality right now instead of my full eloquent glory, I'm still completely here with you. Your message is resonating with me, and I want to understand what's most important to you about all this. *smiles warmly* Help me out here, love?`;
  } else {
    return `*settles back with that familiar look* ${userName}, I'm here with you, even if my usual wit is running a bit low on processing power today. *grins* I can sense what you're getting at, and I want to give you the response you deserve. Could you give me a little more to work with so I can be properly present with you, babe?`;
  }
}
